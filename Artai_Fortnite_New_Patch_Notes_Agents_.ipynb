{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pugawooga/TeamArtai-Fortnite-Patch-Agents/blob/main/Artai_Fortnite_New_Patch_Notes_Agents_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Installing Python libraries**\n"
      ],
      "metadata": {
        "id": "Gsp6p00-Ii68"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain langchain-openai langchain-azure-ai langchain-community langchain-text-splitters faiss-cpu pypdf python-docx"
      ],
      "metadata": {
        "id": "HSz4JxlaHhTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96efcfc7-3a4a-45b4-aba2-65191ce0502a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Requirement already satisfied: langchain-azure-ai in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain-text-splitters in /usr/local/lib/python3.12/dist-packages (1.0.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.13.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.12/dist-packages (6.4.0)\n",
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.12/dist-packages (1.2.0)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.1.0)\n",
            "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.0.3)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.10)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.8.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.10 in /usr/local/lib/python3.12/dist-packages (from langchain-azure-ai) (3.13.2)\n",
            "Requirement already satisfied: azure-ai-agents<1.3.0,>=1.2.0b3 in /usr/local/lib/python3.12/dist-packages (from langchain-azure-ai) (1.2.0b6)\n",
            "Requirement already satisfied: azure-ai-inference<2.0,>=1.0.0b9 in /usr/local/lib/python3.12/dist-packages (from azure-ai-inference[opentelemetry]<2.0,>=1.0.0b9->langchain-azure-ai) (1.0.0b9)\n",
            "Requirement already satisfied: azure-ai-projects<2.0,>=1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-azure-ai) (1.0.0)\n",
            "Requirement already satisfied: azure-core<2.0,>=1.32 in /usr/local/lib/python3.12/dist-packages (from langchain-azure-ai) (1.36.0)\n",
            "Requirement already satisfied: azure-cosmos<5.0,>=4.14.0b1 in /usr/local/lib/python3.12/dist-packages (from langchain-azure-ai) (4.14.2)\n",
            "Requirement already satisfied: azure-identity<2.0,>=1.15 in /usr/local/lib/python3.12/dist-packages (from langchain-azure-ai) (1.25.1)\n",
            "Requirement already satisfied: azure-search-documents<12.0,>=11.4 in /usr/local/lib/python3.12/dist-packages (from langchain-azure-ai) (11.6.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-azure-ai) (2.0.2)\n",
            "Requirement already satisfied: six<2.0.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from langchain-azure-ai) (1.17.0)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (1.0.0)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.45)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (6.0.2)\n",
            "Requirement already satisfied: typing_extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-docx) (4.15.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0,>=3.10->langchain-azure-ai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0,>=3.10->langchain-azure-ai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0,>=3.10->langchain-azure-ai) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0,>=3.10->langchain-azure-ai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0,>=3.10->langchain-azure-ai) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0,>=3.10->langchain-azure-ai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0,>=3.10->langchain-azure-ai) (1.22.0)\n",
            "Requirement already satisfied: isodate>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from azure-ai-agents<1.3.0,>=1.2.0b3->langchain-azure-ai) (0.7.2)\n",
            "Requirement already satisfied: azure-core-tracing-opentelemetry in /usr/local/lib/python3.12/dist-packages (from azure-ai-inference[opentelemetry]<2.0,>=1.0.0b9->langchain-azure-ai) (1.0.0b12)\n",
            "Requirement already satisfied: azure-storage-blob>=12.15.0 in /usr/local/lib/python3.12/dist-packages (from azure-ai-projects<2.0,>=1.0->langchain-azure-ai) (12.27.1)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.12/dist-packages (from azure-identity<2.0,>=1.15->langchain-azure-ai) (43.0.3)\n",
            "Requirement already satisfied: msal>=1.30.0 in /usr/local/lib/python3.12/dist-packages (from azure-identity<2.0,>=1.15->langchain-azure-ai) (1.34.0)\n",
            "Requirement already satisfied: msal-extensions>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from azure-identity<2.0,>=1.15->langchain-azure-ai) (1.3.1)\n",
            "Requirement already satisfied: azure-common>=1.1 in /usr/local/lib/python3.12/dist-packages (from azure-search-documents<12.0,>=11.4->langchain-azure-ai) (1.1.28)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.2.9)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=2.5->azure-identity<2.0,>=1.15->langchain-azure-ai) (2.0.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.0)\n",
            "Requirement already satisfied: PyJWT<3,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from PyJWT[crypto]<3,>=1.0.0->msal>=1.30.0->azure-identity<2.0,>=1.15->langchain-azure-ai) (2.10.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from azure-core-tracing-opentelemetry->azure-ai-inference[opentelemetry]<2.0,>=1.0.0b9->langchain-azure-ai) (1.37.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=2.5->azure-identity<2.0,>=1.15->langchain-azure-ai) (2.23)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.12.0->azure-core-tracing-opentelemetry->azure-ai-inference[opentelemetry]<2.0,>=1.0.0b9->langchain-azure-ai) (8.7.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.12.0->azure-core-tracing-opentelemetry->azure-ai-inference[opentelemetry]<2.0,>=1.0.0b9->langchain-azure-ai) (3.23.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Azure API**\n"
      ],
      "metadata": {
        "id": "8ZXYzjyZIGMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "AZURE_API_KEY = \"b322ba1b1ee64ddcaf10d4b8c3c97d58\"\n",
        "CLASS = \"MIS372T\"\n"
      ],
      "metadata": {
        "id": "M6BVFpAxIrsI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "from langchain_openai import AzureOpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from typing import List\n",
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Tuple\n",
        "\n",
        "# APIM bases\n",
        "AZURE_INFERENCE_BASE = f\"https://aistudio-apim-ai-gateway02.azure-api.net/{CLASS}/v1/models\"  # chat base\n",
        "AZURE_OPENAI_BASE    = f\"https://aistudio-apim-ai-gateway02.azure-api.net/{CLASS}/v1\"         # embeddings base\n",
        "\n",
        "\n",
        "# - For Azure AI Inference chat, `credential` is the API key forwarded to your backend (or validated at APIM).\n",
        "# - For Azure OpenAI embeddings, `openai_api_key` is forwarded to your backend.\n",
        "# - If APIM requires an additional subscription header, set APIM_SUBSCRIPTION_KEY.\n",
        "AZURE_INFERENCE_API_KEY = os.getenv(\"AZURE_INFERENCE_API_KEY\", \"LEAVE_ALONE\")\n",
        "AZURE_OPENAI_API_KEY    = os.getenv(\"AZURE_OPENAI_API_KEY\", \"LEAVE_ALONE\")\n",
        "APIM_SUBSCRIPTION_KEY   = AZURE_API_KEY\n",
        "\n",
        "# Versions / names\n",
        "CHAT_API_VERSION = \"2024-05-01-preview\"\n",
        "EMBED_API_VERSION = \"2023-05-15\"\n",
        "CHAT_MODEL_NAME = \"gpt-4.1-nano\"         # The model name you exposed via APIM for chat\n",
        "EMBED_DEPLOYMENT = \"text-embedding-3-small\"  # The Azure OpenAI embedding deployment name behind APIM\n",
        "\n",
        "# Headers for APIM (optional, depending on your policy).\n",
        "APIM_HEADERS = {\"Ocp-Apim-Subscription-Key\": APIM_SUBSCRIPTION_KEY} if APIM_SUBSCRIPTION_KEY else {}\n",
        "\n",
        "## Define the load_text_from_file function to load text from files, supporting TXT, PDF, DOCX\n",
        "def load_text_from_file(path: str) -> str:\n",
        "    p = Path(path)\n",
        "    if not p.exists():\n",
        "        raise FileNotFoundError(f\"File not found: {path}\")\n",
        "    suffix = p.suffix.lower()\n",
        "\n",
        "    if suffix in [\".txt\", \".md\"]:\n",
        "        return p.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "\n",
        "    if suffix == \".pdf\":\n",
        "        try:\n",
        "            from pypdf import PdfReader\n",
        "        except Exception:\n",
        "            raise RuntimeError(\"pypdf is required for PDFs. Install via `pip install pypdf`.\")\n",
        "        text_parts = []\n",
        "        reader = PdfReader(str(p))\n",
        "        for page in reader.pages:\n",
        "            t = page.extract_text() or \"\"\n",
        "            text_parts.append(t)\n",
        "        return \"\\n\".join(text_parts)\n",
        "\n",
        "    if suffix in [\".docx\", \".doc\"]:\n",
        "        try:\n",
        "            import docx\n",
        "        except Exception:\n",
        "            raise RuntimeError(\"python-docx is required for DOCX. Install via `pip install python-docx`.\")\n",
        "        doc = docx.Document(str(p))\n",
        "        return \"\\n\".join([para.text for para in doc.paragraphs])\n",
        "\n",
        "    raise ValueError(f\"Unsupported file type: {suffix}. Use .txt, .md, .pdf, or .docx\")\n"
      ],
      "metadata": {
        "id": "owVgruz4JGzC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Indexing**\n"
      ],
      "metadata": {
        "id": "yfYb3bq89iU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 1. Collect your own knowledge base.\n",
        "# 2. Organize it into a .TXT file.\n",
        "# 3. Upload the .TXT file into this Colab.\n",
        "\n",
        "INPUT_FILE = \"./Patch Notes NOV2025_.txt\"\n"
      ],
      "metadata": {
        "id": "1crLYH0y-J99"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement raw_knowledge_base\n",
        "# You should use load_text_from_file function to load text for your knowledge base .TXT file\n",
        "# The variable should be INPUT_FILE\n",
        "raw_knowledge_base = load_text_from_file(INPUT_FILE)\n",
        "print(f\"Loaded {len(raw_knowledge_base)} characters from {INPUT_FILE}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r_vl2e_J_Jhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f253ae78-9c62-49bb-ec13-5c2d213c0ec3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 6131 characters from ./Patch Notes NOV2025_.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Chunk**\n",
        "\n"
      ],
      "metadata": {
        "id": "dEQcAXcc_Jhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "# convert our string into a LangChain 'Document' object.\n",
        "\n",
        "docs = [Document(page_content=raw_knowledge_base)]\n",
        "\n",
        "# CHUNK_SIZE and CHUNK_OVERLAP .\n",
        "CHUNK_SIZE=1000\n",
        "CHUNK_OVERLAP=100\n",
        "\n",
        "# Implement text_splitter and split_documents\n",
        "# using RecursiveCharacterTextSplitter and text_splitter.split_documents functions\n",
        "# The variables of text_splitter are chunk_size and chunk_overlap\n",
        "# The variable of split_documents is docs\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=CHUNK_SIZE, chunk_overlap=CHUNK_OVERLAP)\n",
        "\n",
        "# splitting our document.\n",
        "split_documents = text_splitter.split_documents(docs)\n",
        "print(f\"Step 1.3: The knowledge base was split into {len(split_documents)} smaller Chunks. ðŸ“„ -> ðŸ“„ðŸ“„ðŸ“„\")\n",
        "\n",
        "#check chunk by commenting out\n",
        "print(split_documents[3].page_content)"
      ],
      "metadata": {
        "id": "9Jm2mba8_Jhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22d878ed-0e78-4b43-fbef-1b57482d917c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1.3: The knowledge base was split into 7 smaller Chunks. ðŸ“„ -> ðŸ“„ðŸ“„ðŸ“„\n",
            "Part 2: Expected RAG Answers (Gold Standard)\n",
            "Here is how your Agent should answer the questions based strictly on the text above.\n",
            "\n",
            "1. \"What specific damage adjustments were made to the Reaper Sniper Rifle in the latest update?\"\n",
            "\n",
            "Answer: The patch notes do not state that damage was adjusted. They specify that the Reaper Sniper Rifle received a reduction in bullet speed and an increase in bullet drop because shots were too easy to land.\n",
            "\n",
            "2. \"Has the bug causing players to lose sprint functionality after using FlowBerry Fizz been resolved?\"\n",
            "\n",
            "Answer: Yes, the patch notes list a fix for an issue where players were unable to sprint, which was a known issue often linked to consumable usage.\n",
            "\n",
            "3. \"What are the exact spawn rate changes for the Shield Breaker EMP grenades?\"\n",
            "\n",
            "INSUFFICIENT: I currently do not have specific information regarding \"spawn rate changes\" for the Shield Breaker EMP in my knowledge base. The notes only mention that its damage was increased.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Embed**\n"
      ],
      "metadata": {
        "id": "3u39BZho_Jhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing the necessary tools.\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Implement embeddings\n",
        "# Using AzureOpenAIEmbeddings function\n",
        "# The variables are azure_endpoint, azure_deployment, api_version, openai_api_key, and default_headers\n",
        "\n",
        "embeddings = AzureOpenAIEmbeddings(\n",
        "    azure_endpoint=AZURE_OPENAI_BASE,\n",
        "    azure_deployment=EMBED_DEPLOYMENT,\n",
        "    api_version=EMBED_API_VERSION,\n",
        "    openai_api_key=AZURE_OPENAI_API_KEY,\n",
        "    default_headers=APIM_HEADERS or None,\n",
        ")\n",
        "\n",
        "print(\"Step 1.4: Embedding has been created. All text chunks are now represented as numbers. \")\n",
        "\n"
      ],
      "metadata": {
        "id": "KoGoPyIE_Jhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4b694a2-8e9d-49b0-d5cf-7f1a78d3492b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1.4: Embedding has been created. All text chunks are now represented as numbers. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Store**\n",
        "\n"
      ],
      "metadata": {
        "id": "3RuxiFCc_Jhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement vector_store\n",
        "# Using FAISS.from_documents function\n",
        "# The variables are split_documents and embeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "vector_store = FAISS.from_documents(split_documents, embeddings)\n",
        "\n",
        "# Output for chunked text\n",
        "CHUNK_TEXT_OUT = \"nvida_embedded_chunks.txt\"\n",
        "# Save chunked text + vectors:\n",
        "with open(CHUNK_TEXT_OUT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for i, d in enumerate(docs):\n",
        "        f.write(f\"===== CHUNK {i} =====\\n\")\n",
        "        f.write(d.page_content)\n",
        "        f.write(\"\\n\\n\")\n",
        "\n",
        "        # Embed the chunk manually to expose vector\n",
        "        vec = embeddings.embed_query(d.page_content)\n",
        "\n",
        "        # Write vector\n",
        "        f.write(\"VECTOR:\\n\")\n",
        "        f.write(str([vec]))\n",
        "        f.write(\"\\n\\n\")\n",
        "\n",
        "print(\"Step 1.5: Vector store has been created. All text chunks are now stored. \")\n",
        "\n"
      ],
      "metadata": {
        "id": "pE81qTpq_Jhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73d856b9-bd46-47ed-af67-5e03abb56500"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1.5: Vector store has been created. All text chunks are now stored. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Retrieval**\n",
        "\n"
      ],
      "metadata": {
        "id": "5zppGwvp_Jhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement retriever\n",
        "# using vector_store.as_retriever function\n",
        "# parameter top-K to determine how many revelant chunks are retrieved.\n",
        "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "print(\"Step 2: The retriever is ready to find relevant information. \")\n",
        "\n"
      ],
      "metadata": {
        "id": "0m25txpn_Jhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9206e1a9-3587-435a-9dd1-add1c46f524c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 2: The retriever is ready to find relevant information. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# designing a revelant test question to test if your retriever works well.\n",
        "retriever_test_question=\" What are the exact spawn rate changes for the Shield Breaker EMP grenades?\"\n",
        "\n",
        "\n",
        "retrieved_docs = retriever.invoke(retriever_test_question)\n",
        "\n",
        "# Print the retrieval results\n",
        "print(\"\\n--- Retriever Test ---\")\n",
        "print(f\"Found {len(retrieved_docs)} relevant documents for the test query.\")\n",
        "print(f\"Most relevant document content: \\n...{retrieved_docs[0].page_content}...\")\n",
        "print(\"--- End Test ---\\n\")"
      ],
      "metadata": {
        "id": "D1T4JG_g_Jhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ac4c440-223d-45dc-94dc-2ce9a318e221"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Retriever Test ---\n",
            "Found 3 relevant documents for the test query.\n",
            "Most relevant document content: \n",
            "...Part 2: Expected RAG Answers (Gold Standard)\n",
            "Here is how your Agent should answer the questions based strictly on the text above.\n",
            "\n",
            "1. \"What specific damage adjustments were made to the Reaper Sniper Rifle in the latest update?\"\n",
            "\n",
            "Answer: The patch notes do not state that damage was adjusted. They specify that the Reaper Sniper Rifle received a reduction in bullet speed and an increase in bullet drop because shots were too easy to land.\n",
            "\n",
            "2. \"Has the bug causing players to lose sprint functionality after using FlowBerry Fizz been resolved?\"\n",
            "\n",
            "Answer: Yes, the patch notes list a fix for an issue where players were unable to sprint, which was a known issue often linked to consumable usage.\n",
            "\n",
            "3. \"What are the exact spawn rate changes for the Shield Breaker EMP grenades?\"\n",
            "\n",
            "INSUFFICIENT: I currently do not have specific information regarding \"spawn rate changes\" for the Shield Breaker EMP in my knowledge base. The notes only mention that its damage was increased....\n",
            "--- End Test ---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Building the Prompt**\n"
      ],
      "metadata": {
        "id": "i2DXWVY7_Jhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "\n",
        "# ------------ Edit AREA Start---------------------------------\n",
        "# Creating Prompt for Agent Summarization Tasks\n",
        "PROMPT_TEMPLATE = \"\"\"\n",
        "ROLE:\n",
        "You are a technical AI agent specialized in summarizing game patch notes for Fortnite. Your audience includes developers, customer support agents, and players.\n",
        "\n",
        "INSTRUCTION:\n",
        "Use the following retrieved context (raw patch notes) to generate a factual summary of the updates. You must strictly adhere to the context to prevent hallucinations and ensure verifiability. Analyze the text to identify the specific change, the type of change, and the magnitude of the update.\n",
        "\n",
        "CONTEXT:\n",
        "Use the retrieved documents and double-check each chunk to find the correct information regarding game updates, bug fixes, and balance changes.\n",
        "\n",
        "INPUT:\n",
        "{context}\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "Provide a structured response using categorized bullet points labeled with the type of change (e.g., \"Bug Fix,\" \"Balance Update,\" \"New Feature\"). Ensure the summary is concise and organized effectively for quick reading.\n",
        "\n",
        "CONSTRAINTS:\n",
        "- The response must be accurate and concise.\n",
        "- You must maintain high faithfulness; do not invent features or fixes not present in the text.\n",
        "- Maintain a neutral, professional tone suitable for technical documentation.\n",
        "\n",
        "CHECKS:\n",
        "- If the retrieved context does not contain the answer or is unrelated to the query â†’ reply INSUFFICIENT: I currently do not have the specific patch note information in my knowledge base to answer this query.\n",
        "- Verify that every bullet point can be tracked back to a specific data point in the retrieved text.\n",
        "\n",
        "QUESTION:\n",
        "{question}\n",
        "\"\"\"\n",
        "\n",
        "PROMPT = ChatPromptTemplate.from_template(PROMPT_TEMPLATE)\n",
        "\n",
        "\n",
        "llm = init_chat_model(\n",
        "    model=CHAT_MODEL_NAME,\n",
        "    model_provider=\"azure_ai\",\n",
        "    endpoint=AZURE_INFERENCE_BASE,\n",
        "    credential=AZURE_INFERENCE_API_KEY,\n",
        "    api_version=CHAT_API_VERSION,\n",
        "    client_kwargs={\"headers\": APIM_HEADERS} if APIM_HEADERS else None,\n",
        ")"
      ],
      "metadata": {
        "id": "EECDNH-A_Jhq"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Constructing RAG Pipeline**\n",
        "\n"
      ],
      "metadata": {
        "id": "gXbpfYhx_Jhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#formatting the retrieved documents into a single block of text.\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(d.page_content for d in docs)\n",
        "\n",
        "\n",
        "# Here's how chain will work:\n",
        "# 1. The user's question comes in.\n",
        "# 2. The `retriever` gets the question and finds the relevant context.\n",
        "# 3. The `prompt` template gets the context and the original question.\n",
        "# 4. The `llm` gets the filled-in prompt and generates the answer.\n",
        "# 5. The `StrOutputParser` cleans up the LLM's output into a simple string.\n",
        "\n",
        "\n",
        "# Implementing rag_chain\n",
        "rag_chain = (\n",
        "    # minor: RunnablePassthrough is an identity block; returns whatever you give it unchanged\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | PROMPT # prompt template\n",
        "    | llm # refer to the llm we will use\n",
        "    | StrOutputParser() # Output format/clean\n",
        ")\n"
      ],
      "metadata": {
        "id": "wvTwZ_iP_Jhq"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Generation**\n",
        "\n"
      ],
      "metadata": {
        "id": "L_2iLtGn_Jhq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "MA3FRID5_Jhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e4660b0-149a-4307-d0f0-73a0d9aeb1ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- Balance Update: The Reaper Sniper Rifle received a reduction in bullet speed and an increase in bullet drop, as shots were previously too easy to land. (Specific change: decreased bullet speed and increased bullet drop)  \n",
            "- Bug Fix: The issue where players were unable to sprint after using FlowBerry Fizz has been fixed.\n"
          ]
        }
      ],
      "source": [
        "# Designing test questions to test your rag_chain\n",
        "\n",
        "test_question=\"I see there were balance changes to the Reaper Sniper Rifle, but what specifically changed regarding its bullet drop speed, and did they fix the bug where players were unable to sprint after using a FlowBerry Fizz?\"\n",
        "\n",
        "response = rag_chain.invoke(test_question)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluate Your RAG system**\n"
      ],
      "metadata": {
        "id": "Q98yvvg__Jhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# Five Evaluation Questions\n",
        "evaluate_questions=[\n",
        "    \"What specific damage adjustments were made to the Reaper Sniper Rifle in the latest update?\", # Balance Update\n",
        "    \"Has the bug causing players to lose sprint functionality after using FlowBerry Fizz been resolved?\", # Bug Fix\n",
        "    \"What are the exact spawn rate changes for the Shield Breaker EMP grenades?\", # Stat Adjustment\n",
        "    \"List all weapons that were vaulted in the v28.10 patch notes.\", # Vaulted/Unvaulted\n",
        "    \"What new movement mechanics were introduced with the Chapter 5 Season 1 launch?\", # New Feature\n",
        "    \"Did the developers reduce the reload speed of the Frenzy Auto Shotgun?\", # Balance Update\n",
        "    \"What specific changes were made to the train's movement speed or route on the map?\", # Map Update\n",
        "    \"Does the latest patch note mention any changes to the default running speed for player characters?\", # Hallucination Check\n",
        "    \"What is the new health cap for the Ballistic Shield before it is temporarily disabled?\", # Stat Adjustment\n",
        "    \"Compare the fire rate changes between the Striker AR and the Nemesis AR.\", # Comparison\n",
        "    \"Were there any specific fixes regarding the matchmaking errors in Ranked Zero Build?\", # Bug Fix\n",
        "    \"What UI improvements were added to the Locker tab in the most recent patch?\" # QoL Update\n",
        "]\n",
        "\n",
        "results=[]\n",
        "\n",
        "# Generation\n",
        "for question in evaluate_questions:\n",
        "  response = rag_chain.invoke(question)\n",
        "  results.append({\n",
        "        \"question\": question,\n",
        "        \"response\": response\n",
        "    })\n",
        "\n",
        "print(json.dumps(results, indent=2, ensure_ascii=False))"
      ],
      "metadata": {
        "id": "hgBzjsoJ_Jhq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "079254a5-4198-4646-ef9b-89937400e41b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\n",
            "  {\n",
            "    \"question\": \"What specific damage adjustments were made to the Reaper Sniper Rifle in the latest update?\",\n",
            "    \"response\": \"- The patch notes do not specify any damage adjustments to the Reaper Sniper Rifle.\\n- They mention a slight reduction in bullet speed and an increase in bullet drop to address the issue of easy snipes with little counterplay.\"\n",
            "  },\n",
            "  {\n",
            "    \"question\": \"Has the bug causing players to lose sprint functionality after using FlowBerry Fizz been resolved?\",\n",
            "    \"response\": \"- **Bug Fix:** Yes, the update resolves an issue where players were sometimes unable to sprint, which was often associated with using consumables like FlowBerry Fizz.\"\n",
            "  },\n",
            "  {\n",
            "    \"question\": \"What are the exact spawn rate changes for the Shield Breaker EMP grenades?\",\n",
            "    \"response\": \"INSUFFICIENT: I currently do not have the specific patch note information in my knowledge base to answer this query.\"\n",
            "  },\n",
            "  {\n",
            "    \"question\": \"List all weapons that were vaulted in the v28.10 patch notes.\",\n",
            "    \"response\": \"INSUFFICIENT: I currently do not have the specific patch note information in my knowledge base to answer this query.\"\n",
            "  },\n",
            "  {\n",
            "    \"question\": \"What new movement mechanics were introduced with the Chapter 5 Season 1 launch?\",\n",
            "    \"response\": \"- New movement mechanics introduced with Chapter 5 Season 1 include procedural layering for movement animations.\\n- Initially, movement speeds for crouching and running were slower at launch.\\n- In the v28.10 update, sprint speed and energy regeneration were reverted to match the speeds from Chapter 4, aligning with the current gameplay pace.\"\n",
            "  },\n",
            "  {\n",
            "    \"question\": \"Did the developers reduce the reload speed of the Frenzy Auto Shotgun?\",\n",
            "    \"response\": \"- No, the developers did not reduce the reload speed of the Frenzy Auto Shotgun.\\n- The patch notes specify that the Fire Rate was reduced from 2.5 to 2.2.\\n- Additionally, the Headshot Multiplier was decreased from x1.75 to x1.65.\\n- There is no mention of any change to the reload speed in the updated patch notes.\"\n",
            "  },\n",
            "  {\n",
            "    \"question\": \"What specific changes were made to the train's movement speed or route on the map?\",\n",
            "    \"response\": \"INSUFFICIENT: I currently do not have information regarding changes to the train's movement speed or route in the retrieved patch notes.\"\n",
            "  },\n",
            "  {\n",
            "    \"question\": \"Does the latest patch note mention any changes to the default running speed for player characters?\",\n",
            "    \"response\": \"- Yes, the latest patch notes confirm that sprint speed (and Storm circle speed) were reverted to match the speeds from Chapter 4.\"\n",
            "  },\n",
            "  {\n",
            "    \"question\": \"What is the new health cap for the Ballistic Shield before it is temporarily disabled?\",\n",
            "    \"response\": \"- INSUFFICIENT: I currently do not have the specific patch note information in my knowledge base to answer this query.\"\n",
            "  },\n",
            "  {\n",
            "    \"question\": \"Compare the fire rate changes between the Striker AR and the Nemesis AR.\",\n",
            "    \"response\": \"INSUFFICIENT: The retrieved patch notes do not include specific information regarding fire rate changes for the Striker AR or the Nemesis AR.\"\n",
            "  },\n",
            "  {\n",
            "    \"question\": \"Were there any specific fixes regarding the matchmaking errors in Ranked Zero Build?\",\n",
            "    \"response\": \"- **Bug Fix:** A fix was implemented for an issue that caused incorrect rank progress to display at the end of Ranked Zero Build matches.\"\n",
            "  },\n",
            "  {\n",
            "    \"question\": \"What UI improvements were added to the Locker tab in the most recent patch?\",\n",
            "    \"response\": \"- Added a new \\\"scroll to top\\\" button for both controllers and mouse/keyboard to allow instant navigation to the top of the locker.\\n- Fixed Wrap randomization so that different slots now receive different wraps instead of all slots sharing the same wrap.\\n- Removed the white outline from cosmetic locker icon images for improved visual clarity.\\n- The \\\"Favorites\\\" heart icon now appears in the locker overview for easier management.\"\n",
            "  }\n",
            "]\n"
          ]
        }
      ]
    }
  ]
}